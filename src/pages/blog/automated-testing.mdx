import Container from "../../components/Container";
import Key from "../../components/Key";

<Container>

# Automated accessibility testing

*We can leverage tooling and automated tests during our development workflow to help us:*

- *uncover "low-hanging fruit" type accessibility issues,*
- *develop accessible components more efficiently,*
- *improve test coverage, and*
- *avoid introducing technical debt.*

---

## Axe core API

[`axe-core`](https://github.com/dequelabs/axe-core) is an open source accessibility rules engine that can be used to empower linters, browser extensions and automated testing tools like `jest` and `cypress` to uncover up to 57% of WCAG issues. Below are the tools I use that leverage this popular API.

## Linter

**Up to 25% of WCAG issues** can be caught whilst coding. [axe Linter](https://marketplace.visualstudio.com/items?itemName=deque-systems.vscode-axe-linter) is a VSCode extension that uses a subset of `axe-core`'s rules engine to catch things like:

- Missing `alt` attribute for images
- Missing `label` for inputs
- Missing accessible text for buttons and links
- Improper use of `tabindex` (positive integer)
- Improper use of ARIA

Linters are an easy way to catch some low-hanging fruit and a great first step to raising awareness of accessibility among an engineering team. When working on a codebase with multiple contributors, we can install [`eslint-plugin-jsx-a11y`](https://github.com/jsx-eslint/eslint-plugin-jsx-a11y), activate the plugin and use it's `recommended` (or `strict`) rule set in the `.eslintrc.json` like so:

```json
{
  "plugins": ["jsx-a11y"],
  "extends": ["plugin:jsx-a11y/recommended"]
}
```

Then using [`lint-staged`](https://github.com/okonet/lint-staged) and [`husky`](https://github.com/typicode/husky) we can enforce these rules by running the `eslint` script pre-commit.

## Browser extension

**Up to 57% of WCAG issues** can be caught by in-browser testing tools. [Axe Devtools Chrome extension](https://chrome.google.com/webstore/detail/axe-devtools-web-accessib/lhdoppojpmngadmnindnejefpokejbdd) can scan a page for things like:

- Insufficient text to background contrast ratios
- Missing or incorrect usage of headings

I prefer axe Devtools to Chrome's Lighthouse as it doesn't reload the page, so any local state, like an open modal, can be preserved when testing.

The Pro version of Axe Devtools includes a series of guided tests that assists you in assessing the structure, images, interactive elements, forms and modals on a page. This can bring your accessibility test coverage to 80%.

## Unit testing

Using unit testing we can automate assertions for things like keyboard support, ARIA states etc. When building components such as a `Checkbox`, `Dialog`, `Tab` etc. I use the [ARIA patterns guide](https://www.w3.org/WAI/ARIA/apg/patterns/) as acceptance criteria. Before building, I write unit test cases for the component based on this criteria for example `"the dialog should close with the escape key"`. This test driven approach helps me build and maintain accessible components more efficiently.

I use `react-testing-library`'s [priority guide](https://testing-library.com/docs/queries/about/#priority) to make use of semantic queries in the most accessible way.

## UI testing

I use [`cypress-axe`](https://github.com/component-driven/cypress-axe) to run the `axe-core` checks as part of my UI testing.

Install the dependencies

```shell
yarn add -D axe-core cypress-axe
```

Add the axe commands to `cypress/support/e2e.js` file so they are available to use on the `cy` object.

```javascript
import "cypress-axe";
```

Now testing can be as simple as: visiting the page, injecting axe and checking the page's accessibility.

```javascript
describe("Home page", () => {
  it("should be accessible", () => {
    cy.visit("/");
    cy.injectAxe();
    cy.checkA11y();
  });
});
```

We can `injectAxe` `beforeEach` test case and `checkA11y` after opening a modal, tooltip, dropdown etc.

---

*⚠️ Please note, automated testing alone does not guarantee what you build is accessible. Some things cannot be automated and require a human to review. This includes how our interface works with assistive technologies such as screen readers and more nuanced things like the quality of image alt text. I've popped the [manual testing](/blog/manual-accessibility-testing) rituals I've managed to incorporate into my workflow so far in another post but it's by no means an exhaustive list.*

</Container>
